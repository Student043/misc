{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import feature_extraction\n",
    "import neologdn\n",
    "import glob\n",
    "import MeCab\n",
    "\n",
    "t = MeCab.Tagger()\n",
    "t.parse('')\n",
    "\n",
    "def tokenizer(content):\n",
    "    nouns = []\n",
    "    for line in filter(bool, content.splitlines()[2:]):\n",
    "        for token in t.parse(line).splitlines()[:-1]:\n",
    "            if '名詞,' in token and '非自立' not in line and '接尾' not in line:\n",
    "                nouns.append(token.split('\\t')[0])\n",
    "    return ' '.join(nouns)\n",
    "    \n",
    "\n",
    "\n",
    "tfv = feature_extraction.text.TfidfVectorizer(input='filename', preprocessor=neologdn.normalize,\n",
    "                                              tokenizer=tokenizer, analyzer='word')\n",
    "X = tfv.fit_transform(glob.glob('/tmp/text/*/*.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = []\n",
    "for directory in glob.glob('/tmp/text/*/'):\n",
    "    label = directory.split('/')[-2]\n",
    "    y += [label] * len(glob.glob(directory + '/*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "import sklearn.metrics\n",
    "import sklearn.naive_bayes\n",
    "\n",
    "def benchmark(clf, X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "    result = clf.predict(X_test)\n",
    "    print(sklearn.metrics.classification_report(y_test, result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "dokujo-tsushin       0.63      0.92      0.75       104\n",
      "it-life-hack       0.00      0.00      0.00        25\n",
      "kaden-channel       0.35      0.83      0.50        83\n",
      "livedoor-homme       1.00      0.09      0.16        47\n",
      "movie-enter       1.00      0.03      0.05        36\n",
      "     peachy       0.00      0.00      0.00        38\n",
      "       smax       0.59      1.00      0.74        72\n",
      "sports-watch       1.00      0.06      0.12        47\n",
      " topic-news       0.00      0.00      0.00        27\n",
      "\n",
      "avg / total       0.56      0.51      0.39       479\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.5.1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/metrics/classification.py:1074: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "benchmark(sklearn.naive_bayes.MultinomialNB(), X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "dokujo-tsushin       0.48      0.99      0.64       104\n",
      "it-life-hack       0.00      0.00      0.00        25\n",
      "kaden-channel       0.56      0.69      0.62        83\n",
      "livedoor-homme       0.00      0.00      0.00        47\n",
      "movie-enter       0.00      0.00      0.00        36\n",
      "     peachy       0.00      0.00      0.00        38\n",
      "       smax       0.44      1.00      0.62        72\n",
      "sports-watch       0.00      0.00      0.00        47\n",
      " topic-news       0.00      0.00      0.00        27\n",
      "\n",
      "avg / total       0.27      0.48      0.34       479\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.5.1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/metrics/classification.py:1074: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "import complement_nb\n",
    "benchmark(complement_nb.ComplementNB(), X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "dokujo-tsushin       0.62      0.99      0.77       104\n",
      "it-life-hack       1.00      0.12      0.21        25\n",
      "kaden-channel       0.74      0.71      0.72        83\n",
      "livedoor-homme       0.89      0.17      0.29        47\n",
      "movie-enter       0.89      0.67      0.76        36\n",
      "     peachy       1.00      0.05      0.10        38\n",
      "       smax       0.48      1.00      0.65        72\n",
      "sports-watch       1.00      0.77      0.87        47\n",
      " topic-news       1.00      0.26      0.41        27\n",
      "\n",
      "avg / total       0.78      0.66      0.60       479\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import negation_nb\n",
    "benchmark(negation_nb.NegationNB(), X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "dokujo-tsushin       0.70      0.91      0.79       104\n",
      "it-life-hack       0.00      0.00      0.00        25\n",
      "kaden-channel       0.32      0.80      0.46        83\n",
      "livedoor-homme       0.00      0.00      0.00        47\n",
      "movie-enter       0.00      0.00      0.00        36\n",
      "     peachy       0.00      0.00      0.00        38\n",
      "       smax       0.53      1.00      0.69        72\n",
      "sports-watch       0.00      0.00      0.00        47\n",
      " topic-news       0.00      0.00      0.00        27\n",
      "\n",
      "avg / total       0.29      0.49      0.35       479\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.5.1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/metrics/classification.py:1074: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "import universalset_nb\n",
    "benchmark(universalset_nb.UniversalSetNB(), X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
